---
title: "About"
updated: "2025-11-09"
---

I’m a machine learning engineer and Ph.D. candidate in Computer Science at The Ohio State University’s Computer Vision Lab, where I collaborate with Dr. Jim Davis on uncertainty-aware multimodal systems that operate in analyst-facing settings. I focus on the messy middle between research demos and production deployment: building selective prediction policies, LLM evaluation harnesses, and monitoring stacks that explain when a model should speak, abstain, or call for human review.

I operate across three domains that keep multimodal and language models dependable:

- **Production-aligned uncertainty quantification** that couples per-class calibration, abstention policies, and selective routing so classifiers and LLM agents know when to say “I don’t know.”
- **Vision-language and LLM evaluation tooling** that stress-tests captioning, retrieval, reasoning, and tool-augmented chains to surface brittleness before analysts or end users encounter it.
- **Multimodal ML infrastructure** that delivers data pipelines, benchmarking harnesses, and lightweight services integrating vision, language, and tabular signals into existing workflows.

Day to day I partner with analysts, product leads, and fellow engineers to align model behavior with mission-critical requirements—bridging the lab’s computer vision heritage with the latest LLM-centric methods. I’m currently exploring 2025 research scientist and machine learning engineering roles where I can deepen this work on multimodal, trustworthy AI systems.
